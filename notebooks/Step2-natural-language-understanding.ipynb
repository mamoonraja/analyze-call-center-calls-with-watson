{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "\n## Notebook 2 \u2013 Natural Language Understanding (NLU)\nNLU analyzes text to extract meta-data from content such as concepts, entities, keywords, categories, relations and semantic roles.\nhttps://www.ibm.com/watson/services/natural-language-understanding/ \nhttps://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/  \n\n\n## Install dependencies\n\nPython\u2019s standard library is very extensive, offering a wide range of facilities. It contains built-in modules like JSON a lightweight data interchange format. https://docs.python.org/2/library/index.html and https://docs.python.org/2/library/json.html\n\nIBM Watson Developer Cloud has a Python client library to quickly get started with the various Watson APIs services. https://pypi.python.org/pypi/watson-developer-cloud\n\nUsing Python with IBM COS: Python support is provided through the Boto 3 library. The boto3 library provides complete access and can source credentials. The IBM COS endpoint must be specified when creating a service resource or low-level client as shown in documentation https://ibm-public-cos.github.io/crs-docs/python\n\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#imports.... Run this each time after restarting the Kernel\n#!pip install watson_developer_cloud\nimport watson_developer_cloud as watson\nimport json\nfrom botocore.client import Config\nimport ibm_boto3\nimport requests\n"
        }, 
        {
            "source": "##  Cloud Object Storage - Add Credentials & Bucket Name\nIf you've not already set up COS - please see Step 1\n\n### Credentials\nCredentials are also created for you when you create project. From service dashboard page select `Service Credentials` from left navigation menu item, and copy/paste the credentials below:\n\n### Bucket name\nBuckets are created for you when you create project. From service dashboard page select `Buckets` from left navigation menu item, and get your bucket name and copy/paste bucket name below:\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# For Cloud Object Storage - populate your own information here from \"SERVICES\" on this page, or Console Dashboard on ibm.com/cloud\n\n# From service dashboard page select Service Credentials from left navigation menu item\ncredentials_os = {\n  \"apikey\": \"\",\n  \"cos_hmac_keys\": {\n    \"access_key_id\": \"\",\n    \"secret_access_key\": \"\"\n  },\n  \"endpoints\": \"https://cos-service.bluemix.net/endpoints\",\n  \"iam_apikey_description\": \"Auto generated apikey during resource-key operation for Instance\",\n  \"iam_apikey_name\": \"\",\n  \"iam_role_crn\": \"\",\n  \"iam_serviceid_crn\": \"\",\n  \"resource_instance_id\": \"\"\n}\n\n# Buckets are created for you when you create project. From service dashboard page select Buckets from left navigation menu item, \ncredentials_os['BUCKET'] = '<bucket_name>' # copy bucket name from COS"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "source": "### Create Watson Natural Language Understanding (NLU) service\n\nTwo options to create a new NLU service.  (1) Above click SERVICES and create/add new LITE version of NLU; or (2) In Console Dashboard in ibm.com/cloud create a LITE NLU services.  Click on 'SERVICE CREDENTIALS' to get creds.\n\nFor more information on creating Watson services, see Notebook 1\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "credentials_nlu = {\n    \"url\": \"\",\n    \"username\": \"\",\n    \"password\": \"\",\n    \"version\": \"2017-02-27\"\n}"
        }, 
        {
            "source": "### Set up Object Storage Client", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "endpoints = requests.get(credentials_os['endpoints']).json()\n\niam_host = (endpoints['identity-endpoints']['iam-token'])\ncos_host = (endpoints['service-endpoints']['cross-region']['us']['public']['us-geo'])\n\nauth_endpoint = \"https://\" + iam_host + \"/oidc/token\"\nservice_endpoint = \"https://\" + cos_host\n\n\nclient = ibm_boto3.client(\n    's3',\n    ibm_api_key_id = credentials_os['apikey'],\n    ibm_service_instance_id = credentials_os['resource_instance_id'],\n    ibm_auth_endpoint = auth_endpoint,\n    config = Config(signature_version='oauth'),\n    endpoint_url = service_endpoint\n   )\n"
        }, 
        {
            "source": "### NLU\n\n- `process_text()` goes throught the text and fetch sentences and concatenate transcript based on chunk size\n- `analyze transcript()` calls natural language understanding endpoint and analyze the transcripe\n- `post_analysis` processes the results and show insights based on response from NLU endpoint", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#NLU\n\nfrom watson_developer_cloud import NaturalLanguageUnderstandingV1\nfrom watson_developer_cloud.natural_language_understanding.features import (\n    v1 as Features)\n\nnatural_language_understanding = NaturalLanguageUnderstandingV1(\n    version = '2017-02-27',\n    username = credentials_nlu['username'],\n    password = credentials_nlu['password']\n)\n\nchunk_size=25 # This CHUNK size is used to disaggregate a transcript \n#e.g. in this case a 290 word transcript would have 10 chunks - 9 with 30 words and 1 with 20 words - approximates 'time domain' for this lab\n\ndef chunk_transcript(transcript, chunk_size):\n    transcript = transcript.split(' ')\n    return [ transcript[i:i+chunk_size] for i in range(0, len(transcript), chunk_size) ] # chunking data\n\ndef process_text(text):\n    transcript=''\n    for sentence in json.loads(text)['results']:\n        transcript = transcript + sentence['alternatives'][0]['transcript'] # concatenate sentences\n    #transcript = chunk_transcript(transcript, chunk_size) # chunk the transcript\n    return  transcript\n\n\ndef analyze_transcript(features, file_name):\n    streaming_body = client.get_object(Bucket = credentials_os['BUCKET'], Key=file_name.split('.')[0]+'_text.json')['Body']\n    transcript = process_text(streaming_body.read().decode(\"utf-8\"))\n    nlu_analysis = natural_language_understanding.analyze(features, transcript, return_analyzed_text=True)\n    res=client.put_object(Bucket = credentials_os['BUCKET'], Key=file_name.split('.')[0]+'_NLU.json', Body= json.dumps(nlu_analysis))\n    return nlu_analysis\n\ndef post_analysis(result):\n    print(result['analyzed_text'])\n    categories = result['categories']\n    for category in categories:\n        print('label: ', category['label'], ', score: ', category['score']) #add table instead of prints\n\n        \ndef process_text_chunks(text):\n    transcript=''\n    for sentence in json.loads(text)['results']:\n        transcript = transcript + sentence['alternatives'][0]['transcript'] # concatenate sentences\n    transcript = chunk_transcript(transcript, chunk_size) # chunk the transcript\n    return  transcript\n\ndef analyze_transcript_chunks(features, file_name):\n    streaming_body = client.get_object(Bucket = credentials_os['BUCKET'], Key=file_name.split('.')[0]+'_text.json')['Body']\n    transcript=streaming_body.read().decode(\"utf-8\")\n    nlu_analysis={}\n    for chunk in process_text_chunks(transcript):\n        chunk = ' '.join(chunk)\n        print('chunk: ', chunk)\n        nlu_analysis[chunk] = natural_language_understanding.analyze(features, chunk, return_analyzed_text=True, language='en')\n    outfilename = file_name.split('.')[0]+'_NLUchunks.json'\n    print(\"writing file: \", outfilename, \" to cloud object storage\" )\n    res=client.put_object(Bucket = credentials_os['BUCKET'], Key=outfilename, Body= json.dumps(nlu_analysis))\n    return nlu_analysis\n\n\ndef post_analysis_chunks(result):\n    for chunk in result.keys():\n        categories = result[chunk]['categories']\n        print('\\nchunk: ', chunk)\n        for category in categories:\n            print('label: ', category['label'], ', score: ', category['score']) #add table instead of prints"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "file_list = ['sample1-addresschange-positive.ogg',\n             'sample2-address-negative.ogg',\n             'sample3-shirt-return-weather-chitchat.ogg',\n             'sample4-angryblender-sportschitchat-recovery.ogg',\n             'sample5-calibration-toneandcontext.ogg',\n             'jfk_1961_0525_speech_to_put_man_on_moon.ogg',\n             'May 1 1969 Fred Rogers testifies before the Senate Subcommittee on Communications.ogg']\n\nfeatures = {\"concepts\":{},\"entities\":{},\"keywords\":{},\"categories\":{},\"emotion\":{},\"sentiment\":{},\"semantic_roles\":{} }"
        }, 
        {
            "source": "Next, we will run NLU enrichment on the transcripts for all audio files. We show two approaches:\n* One NLU call per audio file: In this case, we get aggregated features for the complete audio file.\n* One NLU call per chunk of audio file where a chunk is 25 words: In this case, we get more granular NLU features.\n\nBoth approaches are valid. The default one we show is the second approach with chunks as that provides more granular sentiment results. In practice, you can decide which is more relevant to your application. If you'd like to try the first approach, you'll need to uncomment the next cell and comment out the cell after that.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "result = analyze_transcript_chunks(features, file_list[0])\npost_analysis_chunks(result)\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "## If you'd like to execute NLU per chunk of audio file (chunk is 25 words), make sure the next lines are uncomments\nfor filename in file_list:\n    print(\"\\n\\nprocessing file: \", filename)\n    result = analyze_transcript_chunks(features,filename)\n    post_analysis_chunks(result)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}